# Apache-Spark
Big data processing.

The RDD api: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html

Additional resources on RDD: https://spark.apache.org/docs/latest/rdd-programming-guide.html

Statistical moments.

Average/mean
Standard deviation.
Skewness.: 
Kurtosis.: A measure of outlier content. 
covariance 
Correlation.

**Plotting with Apache Spark and pythin's matplotlib.**

**ML pipelines in Apache spark.** SPARKML.
- used to automate preprocessing steps/feature selection. 
- e.g [data source]- string indexing, normalization, one hot encoding, modelling (version a - z)
- Pipeline has 3 funtions: fit, evaluate and score. 

**ETL**
- this is recommended to be your first notebook per project.
- responsible for sourcing the data and performing basic transfromations before storing to an object storage on the cloud. (watson studio)
- 
